{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a4ghxmpsciR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOaeDDVntFPo"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d atharv1610/terrain-recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEvJmaHhtFhX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/terrain-recognition.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2mw19yjwFBN"
      },
      "outputs": [],
      "source": [
        "zip_ref"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fj5wGrxyd67"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir=pathlib.Path(\"/content/Data Main/test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fapC0o4uz-4x"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.png')))\n",
        "print(image_count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb8jcx2JmFFY"
      },
      "outputs": [],
      "source": [
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSFD-WY13Wv8"
      },
      "outputs": [],
      "source": [
        "M = list(data_dir.glob('Marshy/*'))\n",
        "PIL.Image.open(str(M[110]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kEoGU-Z32-o"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYmChRbu4MU2"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqZVREmN4QKV"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.9,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9vqgqGY4cjV"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V02RToqM4gQB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBWFMbVB4sTl"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP1xbtT-4yDd"
      },
      "outputs": [],
      "source": [
        "normalization_layer = tf.keras.layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IltRMqJo43I3"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EOsQPJt4-qZ"
      },
      "outputs": [],
      "source": [
        "#AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "#train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXncKmMZ5Bj7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.01),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.01),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128),\n",
        "    tf.keras.layers.LeakyReLU(alpha=0.01),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0-O3Y3s5FIn"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-YP9tcQ5IfH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "syxBLGyIK9Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_accurarcies = []\n",
        "model_names = ['CNN', 'VGG16', 'ResNet50', 'MobileNetV2', 'EfficientNetB0']"
      ],
      "metadata": {
        "id": "U_iCqm5m72hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on training and validation datasets\n",
        "train_loss, train_accuracy = model.evaluate(train_ds, verbose=0)\n",
        "val_loss, val_accuracy = model.evaluate(val_ds, verbose=0)\n",
        "validation_accurarcies.append(val_accuracy)\n",
        "# Print the evaluation metrics\n",
        "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "rqyDYtk0gfL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    predictions = model.predict(images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(predicted_classes)\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=val_ds.class_names, digits=4)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "TSGqZ2mc57zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract metrics from history\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xxanJxYEgfL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2, InceptionV3, EfficientNetB0\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "# Function to create a transfer learning model\n",
        "def create_transfer_model(base_model, num_classes, input_shape=(180, 180, 3)):\n",
        "    base_model.trainable = False  # Freeze the pre-trained layers\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.GlobalAveragePooling2D(),  # Pooling layer\n",
        "        layers.Dense(128, activation='relu'),  # Fully connected layer\n",
        "        layers.Dropout(0.5),  # Regularization\n",
        "        layers.Dense(num_classes, activation='softmax')  # Output layer\n",
        "    ])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "GZXExi4DVbEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG16"
      ],
      "metadata": {
        "id": "pejgMUf9VdUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow one-hot encoding function\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the number of classes (5 in this case, based on your dataset)\n",
        "num_classes = len(train_ds.class_names)\n",
        "\n",
        "# Function to convert integer labels to one-hot encoded labels\n",
        "def one_hot_encode(image, label):\n",
        "    label = tf.one_hot(label, depth=num_classes)\n",
        "    return image, label\n",
        "\n",
        "# Apply one-hot encoding to both training and validation datasets\n",
        "train_ds = train_ds.map(one_hot_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(one_hot_encode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Prefetch the datasets to optimize performance\n",
        "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "pUz0c8WVdPad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "vgg16_model = create_transfer_model(vgg16_base, num_classes)\n",
        "\n",
        "vgg16_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                    loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training VGG16 Model\")\n",
        "history1 = vgg16_model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
      ],
      "metadata": {
        "id": "7tla9oq_VfKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model.summary()"
      ],
      "metadata": {
        "id": "QG1rb1UiUmcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on training and validation datasets\n",
        "train_loss, train_accuracy = vgg16_model.evaluate(train_ds, verbose=0)\n",
        "val_loss, val_accuracy = vgg16_model.evaluate(val_ds, verbose=0)\n",
        "validation_accurarcies.append(val_accuracy)\n",
        "# Print the evaluation metrics\n",
        "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "wVuV6z4YftXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    predictions = vgg16_model.predict(images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(predicted_classes)\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "lw8qjJOZ6F3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract metrics from history\n",
        "acc = history1.history['accuracy']\n",
        "val_acc = history1.history['val_accuracy']\n",
        "loss = history1.history['loss']\n",
        "val_loss = history1.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQTVFC5tf4cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50"
      ],
      "metadata": {
        "id": "tvG-GCRkVgdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "resnet_model = create_transfer_model(resnet_base, num_classes)\n",
        "\n",
        "resnet_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                     loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training ResNet50 Model\")\n",
        "history2 = resnet_model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
      ],
      "metadata": {
        "id": "j_2Vx1kwViif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on training and validation datasets\n",
        "train_loss, train_accuracy = resnet_model.evaluate(train_ds, verbose=0)\n",
        "val_loss, val_accuracy = resnet_model.evaluate(val_ds, verbose=0)\n",
        "validation_accurarcies.append(val_accuracy)\n",
        "# Print the evaluation metrics\n",
        "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Orxoicb6gA0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    predictions = resnet_model.predict(images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(predicted_classes)\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "7et-mIpw6QKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "8hvBz_bLUjHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract metrics from history\n",
        "acc = history2.history['accuracy']\n",
        "val_acc = history2.history['val_accuracy']\n",
        "loss = history2.history['loss']\n",
        "val_loss = history2.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCijJBZAgA0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNetV2"
      ],
      "metadata": {
        "id": "BxC7FDveVjko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "mobilenet_model = create_transfer_model(mobilenet_base, num_classes)\n",
        "\n",
        "mobilenet_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "\n",
        "                        loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training MobileNetV2 Model\")\n",
        "history3 = mobilenet_model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
      ],
      "metadata": {
        "id": "LxGWkddhVk5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_model.summary()"
      ],
      "metadata": {
        "id": "8fUXre8YU3_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on training and validation datasets\n",
        "train_loss, train_accuracy = mobilenet_model.evaluate(train_ds, verbose=0)\n",
        "val_loss, val_accuracy = mobilenet_model.evaluate(val_ds, verbose=0)\n",
        "validation_accurarcies.append(val_accuracy)\n",
        "# Print the ev\n",
        "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Ox9qRxsKgNFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    predictions = mobilenet_model.predict(images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(predicted_classes)\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names, digits=4)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "9s8rQIVb6TqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract metrics from history\n",
        "acc = history3.history['accuracy']\n",
        "val_acc = history3.history['val_accuracy']\n",
        "loss = history3.history['loss']\n",
        "val_loss = history3.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ALUruZQ8gNFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EfficientNetB0"
      ],
      "metadata": {
        "id": "eCi4rgNbVpdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(180, 180, 3))\n",
        "efficientnet_model = create_transfer_model(efficientnet_base, num_classes)\n",
        "\n",
        "efficientnet_model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "                           loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Training EfficientNetB0 Model\")\n",
        "history5 = efficientnet_model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
      ],
      "metadata": {
        "id": "YWBU9SBUVrY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "id": "4jizAh5xVEe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on training and validation datasets\n",
        "train_loss, train_accuracy = efficientnet_model.evaluate(train_ds, verbose=0)\n",
        "val_loss, val_accuracy = efficientnet_model.evaluate(val_ds, verbose=0)\n",
        "validation_accurarcies.append(val_accuracy)\n",
        "# Print the evaluation metrics\n",
        "print(f\"Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "gxLrbk83gVuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "for images, labels in val_ds:\n",
        "    predictions = efficientnet_model.predict(images)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    true_labels.extend(labels.numpy())\n",
        "    predicted_labels.extend(predicted_classes)\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=val_ds.class_names, digits=4)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "KeXCQXcp6a3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract metrics from history\n",
        "acc = history5.history['accuracy']\n",
        "val_acc = history5.history['val_accuracy']\n",
        "loss = history5.history['loss']\n",
        "val_loss = history5.history['val_loss']\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BnZSbU3ngVuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(range(len(model_names)), validation_accurarcies, color='skyblue') # Use index as x-axis\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracies of Different Models on the Same Dataset')\n",
        "plt.xticks(range(len(model_names)), model_names, rotation=45) # Set xtick labels explicitly\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pg1u3hoM8hhZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}